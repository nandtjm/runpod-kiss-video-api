# Minimal Dockerfile - Working API without large models
# Models will be downloaded at runtime on first request
FROM --platform=linux/amd64 runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    curl \
    unzip \
    ffmpeg \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgoogle-perftools4 \
    libtcmalloc-minimal4 \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables
ENV PYTHONPATH=/app
ENV CUDA_HOME=/usr/local/cuda
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
ENV PYTHONUNBUFFERED=1
ENV MODEL_CACHE_DIR=/workspace/models
ENV TEMP_DIR=/workspace/temp
ENV HUGGINGFACE_HUB_CACHE=/workspace/models/.cache

# Create directories
RUN mkdir -p /workspace/models /workspace/temp /workspace/models/.cache

# Copy requirements and install Python dependencies
COPY requirements.txt ./
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Install PyTorch with CUDA support
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install additional dependencies for model downloads
RUN pip install huggingface_hub transformers

# Copy application code
COPY . .

# Create startup script that uses volume models
RUN echo '#!/bin/bash\n\
echo "ðŸš€ Starting Kiss Video Generator API"\n\
echo "ðŸ“¦ Using pre-loaded models from volume"\n\
echo "âš¡ API starting on port 8000"\n\
python3 main_volume.py\n\
' > /app/start.sh && chmod +x /app/start.sh

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
  CMD curl -f http://localhost:8000/health || exit 1

# Start API (models download on demand)
CMD ["/app/start.sh"]