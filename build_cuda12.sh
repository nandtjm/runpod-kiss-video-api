#!/bin/bash

# Build CUDA 12.x Compatible RunPod Serverless Image
# Fixes CUDA version mismatch issues

set -e

echo "üöÄ Building CUDA 12.x Compatible RunPod Serverless Image"
echo "========================================================"
echo ""

# Configuration
IMAGE_NAME="kiss-video-generator"
TAG="cuda12"
REGISTRY="nandtjm"
FULL_IMAGE="$REGISTRY/$IMAGE_NAME:$TAG"

echo "üìã Build Configuration:"
echo "  Purpose: Fix CUDA version compatibility"
echo "  Base Image: runpod/pytorch:2.1.0-py3.10-cuda12.1.0-devel-ubuntu22.04"
echo "  Image: $FULL_IMAGE"
echo "  CUDA Version: 12.1 (RunPod compatible)"
echo "  PyTorch: 2.1.0+ with CUDA 12.1 support"
echo ""

echo "üîç CUDA Compatibility Fix:"
echo "  ‚ùå Previous: CUDA 11.8 (incompatible)"
echo "  ‚úÖ New: CUDA 12.1 (RunPod requirement)"
echo "  ‚úÖ PyTorch from cu121 index"
echo "  ‚úÖ All GPU operations should work"
echo ""

# Check required files
echo "üîç Verifying required files..."
REQUIRED_FILES=(
    "handler.py"
    "runpod_serverless.py" 
    "Dockerfile.cuda12"
    "requirements_cuda12.txt"
)

for file in "${REQUIRED_FILES[@]}"; do
    if [ ! -f "$file" ]; then
        echo "‚ùå Missing required file: $file"
        exit 1
    fi
    echo "  ‚úÖ $file"
done

echo ""

# Enable BuildKit
export DOCKER_BUILDKIT=1

echo "üî® Building CUDA 12.x compatible Docker image..."
echo "‚è±Ô∏è  This may take 3-5 minutes (installing PyTorch with CUDA 12.1)"
echo ""

# Build with CUDA 12.x Dockerfile
docker build \
    --platform=linux/amd64 \
    -f Dockerfile.cuda12 \
    -t "$FULL_IMAGE" \
    --progress=plain \
    .

if [ $? -eq 0 ]; then
    echo ""
    echo "‚úÖ CUDA 12.x build successful!"
    echo ""
    
    # Show image info
    echo "üìä Image Information:"
    docker images "$FULL_IMAGE" --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}"
    echo ""
    
    # Test CUDA in built image
    echo "üß™ Testing CUDA compatibility in built image..."
    docker run --rm "$FULL_IMAGE" python3 -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
else:
    print('Note: CUDA test requires GPU, but build is compatible')
"
    
    echo ""
    echo "üöÄ Next Steps to Fix CUDA Issue:"
    echo ""
    echo "1. üì§ Push the CUDA 12.x compatible image:"
    echo "   docker push $FULL_IMAGE"
    echo ""
    echo "2. üîß Update your RunPod serverless endpoint:"
    echo "   - Docker Image: $FULL_IMAGE"
    echo "   - This should resolve the CUDA version mismatch"
    echo ""
    echo "3. üß™ Test the endpoint:"
    echo "   curl -X POST \"https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run\" \\"
    echo "     -H \"Authorization: Bearer YOUR_API_KEY\" \\"
    echo "     -H \"Content-Type: application/json\" \\"
    echo "     -d '{\"input\": {\"test_mode\": true}}'"
    echo ""
    echo "4. üéØ Expected CUDA info in response:"
    echo "   {"
    echo "     \"environment\": {"
    echo "       \"torch_available\": true,"
    echo "       \"cuda_available\": true,"
    echo "       \"torch_version\": \"2.1.0+cu121\""
    echo "     }"
    echo "   }"
    echo ""
    
    # Ask about pushing
    read -p "ü§î Push CUDA 12.x image to Docker Hub now? (y/N): " -n 1 -r
    echo ""
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "üì§ Pushing CUDA 12.x image to Docker Hub..."
        docker push "$FULL_IMAGE"
        
        if [ $? -eq 0 ]; then
            echo ""
            echo "‚úÖ CUDA 12.x image pushed successfully!"
            echo ""
            echo "üéâ Ready to Fix CUDA Compatibility!"
            echo ""
            echo "üìã Updated Checklist:"
            echo "  1. ‚úÖ CUDA 12.x compatible image built and pushed"
            echo "  2. ‚è≥ Update endpoint Docker image to: $FULL_IMAGE"
            echo "  3. ‚è≥ Test endpoint (should now work with GPU)"
            echo "  4. ‚è≥ Celebrate working CUDA! üéä"
            echo ""
            echo "üí° The CUDA mismatch should now be resolved."
            echo "   Your endpoint will have proper GPU acceleration."
        else
            echo "‚ùå Push failed. Please check Docker Hub credentials."
        fi
    else
        echo "‚è≥ Push later with: docker push $FULL_IMAGE"
    fi
    
else
    echo ""
    echo "‚ùå Build failed. Check output above for errors."
    echo ""
    echo "üîß Common CUDA build issues:"
    echo "  - Network timeout during PyTorch download"
    echo "  - Insufficient disk space"
    echo "  - Docker BuildKit not enabled"
    echo ""
    echo "Try running again or check Docker daemon status."
    exit 1
fi