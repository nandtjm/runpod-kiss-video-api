# Production Dockerfile with Pre-loaded AI Models
# This builds models into the Docker image at build time instead of downloading at runtime
FROM runpod/pytorch:2.1.0-py3.10-cuda11.8.0-devel-ubuntu22.04

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    wget \
    curl \
    unzip \
    ffmpeg \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    libgoogle-perftools4 \
    libtcmalloc-minimal4 \
    && rm -rf /var/lib/apt/lists/*

# Set environment variables for model paths
ENV PYTHONPATH=/app
ENV CUDA_HOME=/usr/local/cuda
ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
ENV PYTHONUNBUFFERED=1
ENV MODEL_CACHE_DIR=/app/models
ENV TEMP_DIR=/app/temp
ENV HUGGINGFACE_HUB_CACHE=/app/models/.cache

# Create model directories
RUN mkdir -p /app/models /app/temp /app/models/.cache

# Copy requirements first for better Docker layer caching
COPY requirements.txt ./

# Install Python dependencies
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Install PyTorch with CUDA support
RUN pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install Hugging Face CLI for model downloading
RUN pip install --no-cache-dir huggingface_hub[cli]

# PRE-LOAD MODELS AT BUILD TIME
# This is the key improvement - models are downloaded during Docker build
RUN echo "Downloading AI models at build time..." && \
    huggingface-cli download Wan-AI/Wan2.1-I2V-14B-720P \
        --local-dir /app/models/Wan2.1-I2V-14B-720P \
        --local-dir-use-symlinks False && \
    echo "✅ Wan-AI model downloaded successfully"

RUN echo "Downloading Remade-AI LoRA..." && \
    huggingface-cli download Remade-AI/kissing \
        --local-dir /app/models/kissing-lora \
        --local-dir-use-symlinks False && \
    echo "✅ Remade-AI LoRA downloaded successfully"

# Verify models were downloaded correctly
RUN echo "Verifying model downloads..." && \
    ls -la /app/models/ && \
    ls -la /app/models/Wan2.1-I2V-14B-720P/ && \
    ls -la /app/models/kissing-lora/ && \
    echo "✅ Model verification complete"

# Copy application code after model downloads for better caching
COPY . .

# Create a simplified main.py that uses pre-loaded models
COPY main_production.py main.py

# Set proper permissions
RUN chmod +x main.py rp_handler.py

# Health check to verify models are accessible
RUN python3 -c "import os; assert os.path.exists('/app/models/Wan2.1-I2V-14B-720P'), 'Wan-AI model not found'; assert os.path.exists('/app/models/kissing-lora'), 'LoRA not found'; print('✅ All models verified')"

# Production RunPod serverless handler
CMD ["python3", "-u", "rp_handler.py"]