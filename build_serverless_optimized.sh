#!/bin/bash

# Build Serverless-Optimized Docker Image
# Uses network volume models - No model downloads!

set -e

echo "üöÄ Building Serverless-Optimized AI Kiss Generator"
echo "================================================="
echo ""

echo "üí° Serverless Optimization Strategy:"
echo "  ‚úÖ Uses pre-existing network volume models"
echo "  ‚úÖ No model downloads during build"
echo "  ‚úÖ Lightweight image (2GB vs 8GB+)"
echo "  ‚úÖ Fast serverless cold starts"
echo "  ‚úÖ Superior RunPod bandwidth for dependencies only"
echo ""

# Configuration
IMAGE_NAME="nandtjm/kiss-video-generator"
TAG="serverless"
FULL_IMAGE="${IMAGE_NAME}:${TAG}"

# Enable Docker BuildKit
export DOCKER_BUILDKIT=1

echo "üìã Build Configuration:"
echo "  Image: ${FULL_IMAGE}"
echo "  Dockerfile: Dockerfile.serverless"
echo "  Strategy: Network volume optimized"
echo "  Expected size: ~2GB (vs 8GB+ with embedded models)"
echo ""

# Check required files
echo "üîç Verifying serverless build files..."
REQUIRED_FILES=(
    "Dockerfile.serverless"
    "handler.serverless.py"
    "requirements.serverless.txt"
    "runpod_serverless.py"
)

for file in "${REQUIRED_FILES[@]}"; do
    if [ ! -f "$file" ]; then
        echo "‚ùå Missing: $file"
        exit 1
    fi
    echo "  ‚úÖ $file"
done

echo ""
echo "üèóÔ∏è Building serverless-optimized image..."
echo ""

time docker build \
    --platform=linux/amd64 \
    --build-arg BUILDKIT_INLINE_CACHE=1 \
    --cache-from="${FULL_IMAGE}" \
    -f Dockerfile.serverless \
    -t "${FULL_IMAGE}" \
    --progress=plain \
    .

if [ $? -eq 0 ]; then
    echo ""
    echo "‚úÖ Serverless build completed!"
    
    # Show image comparison
    echo ""
    echo "üìä Image Size Comparison:"
    echo "========================="
    echo "Previous production image (with embedded models):"
    docker images "${IMAGE_NAME}:production" --format "  {{.Repository}}:{{.Tag}}  {{.Size}}" 2>/dev/null || echo "  Not available"
    echo ""
    echo "New serverless image (network volume optimized):"
    docker images "${FULL_IMAGE}" --format "  {{.Repository}}:{{.Tag}}  {{.Size}}"
    
    # Push to Docker Hub
    echo ""
    read -p "üöÄ Push serverless image to Docker Hub? (y/N): " -n 1 -r
    echo ""
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        echo "üì§ Pushing serverless image..."
        time docker push "${FULL_IMAGE}"
        
        if [ $? -eq 0 ]; then
            echo ""
            echo "üéâ Serverless Image Deployed Successfully!"
            echo "========================================"
            echo ""
            echo "‚úÖ Image: ${FULL_IMAGE}"
            echo "‚úÖ Optimized for network volume models"
            echo "‚úÖ Fast serverless deployment"
            echo "‚úÖ No model downloads required"
            echo ""
            echo "üöÄ Deployment Instructions:"
            echo "=========================="
            echo ""
            echo "1. Create RunPod Serverless Endpoint:"
            echo "   - Docker Image: ${FULL_IMAGE}"
            echo "   - Network Volume: ai-models-kiss-video (100GB)"
            echo "   - Mount Path: /runpod-volume"
            echo "   - GPU: RTX 4090/5090"
            echo ""
            echo "2. Environment Variables:"
            echo "   MODEL_CACHE_DIR=/runpod-volume/models"
            echo "   CUDA_LAUNCH_BLOCKING=0"
            echo ""
            echo "3. Test Health Check:"
            echo '   curl -X POST "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run" \'
            echo '     -H "Authorization: Bearer YOUR_API_KEY" \'
            echo '     -d '"'"'{"input": {"health_check": true}}'"'"''
            echo ""
            echo "4. Expected Response:"
            echo '   {"status": "healthy", "models_ready": true}'
            echo ""
            echo "5. Generate Kiss Video:"
            echo '   curl -X POST "https://api.runpod.ai/v2/YOUR_ENDPOINT_ID/run" \'
            echo '     -H "Authorization: Bearer YOUR_API_KEY" \'
            echo '     -d '"'"'{"input": {"source_image": "BASE64_IMG1", "target_image": "BASE64_IMG2"}}'"'"''
            echo ""
            echo "üéØ Key Benefits:"
            echo "==============="
            echo "  ‚ö° 70% smaller image size"
            echo "  üöÄ Faster cold starts"
            echo "  üí∞ Lower compute costs"
            echo "  üì¶ Uses your existing network volume models"
            echo "  üî• Same AI video quality"
            echo ""
            echo "üé¨ Ready to generate AI kiss videos with your network volume models! ‚ú®"
        fi
    else
        echo ""
        echo "‚ÑπÔ∏è  Image built but not pushed. You can push later with:"
        echo "   docker push ${FULL_IMAGE}"
    fi
else
    echo "‚ùå Build failed!"
    echo ""
    echo "üîç Common Issues:"
    echo "  - Docker daemon not running"
    echo "  - Missing build files"
    echo "  - Network connectivity issues"
    echo "  - Insufficient disk space"
    echo ""
    exit 1
fi

echo ""
echo "üí° Why This Approach Is Superior:"
echo "================================="
echo ""
echo "‚ùå Old approach (Dockerfile.production):"
echo "  - Downloaded models during build (slow)"
echo "  - 8GB+ image size"
echo "  - Duplicated models (network volume + image)"
echo "  - Expensive bandwidth during build"
echo ""
echo "‚úÖ New approach (Dockerfile.serverless):"
echo "  - Uses existing network volume models"
echo "  - ~2GB image size"
echo "  - Single source of truth for models"
echo "  - Fast builds and deployments"
echo ""
echo "üéØ Result: Same AI generation, optimized infrastructure!"